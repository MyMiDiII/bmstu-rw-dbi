\chapter{Описание существующих методов построения индексов\label{methods}}

По структуре индексы подразделяются на
\begin{itemize}
    \item упорядоченные, на основе деревьев поиска,
    \item индексы на основе хеш-таблиц,
    \item индексы на основе битовых карт.
\end{itemize}

\section{Индексы на основе деревьев поиска}

B-tree индексы можно рассматривать как модель сопоставления ключа позиции
искомой записи в отсортированном массиве~(рисунок~\ref{img:btree}).

\imgs{btree}{h!}{0.4}{B-деревья}

Такие индексы как бы предсказывают положение записи с минимаксной ошибкой
($min\_err = 0$, $max\_err = page\_size$). Поэтому можем заминить B-деревья на
линейную модель также с минимаксной ошибкой~(рисунок~\ref{img:learnedbtree}).

\imgs{learnedbtree}{h!}{0.4}{Обученный индекс}

Так для предсказания можно представлять Range Index Models как модели функции
распределения~(рисунок~\ref{img:cdf}):

\begin{equation}
    \text{position} = F(key) \cdot N,
\end{equation}

где $F(key)$ --- функция распределения, дающая оценку вероятности обнаружения
ключа, меньшего или равного ключу поиска, то есть $P(X < key)$;

~~~~$N$ --- количество ключей.

\imgs{cdf}{h!}{0.4}{Индекс как функция распределения}

Можно построить индексы на основе рекурсивной
модели~(рисунок~\ref{img:hiermodel}), в которой строится иерархия моделей из n
уровней. Каждая модель на вход получает ключ, на основе которого выбирает модель
на следующем уровне. Модели последнего этапа предсказывают положение записи.

\imgs{hiermodel}{h!}{0.4}{Рекурсивная модель индекса}

Можно использовать различные модели: например, на верхнем использовать нейронные
сети, а на нижних простые линейные регрессионные модели или даже простые
B-деревья.

\section{Индексы на основе хеш-таблиц}

Хеш-индексы можно рассматривать как модель сопоставления ключа позиции
искомой записи в неупорядоченном массиве.

\imgs{hash}{h!}{0.5}{Хеш-индексы}

Функция распределения вероятностей распределения ключей  один из возможных
способов обучения хеш-индексов. Функция распределения масштабируется на размер
хеш-таблицы $M$ и для поиска положения записи аналогично случаю с B-деревьями
используется формула:

\begin{equation}
    h(K) = F(K) \cdot M,
\end{equation}

где $K$ --- ключ.

\section{Индексы на основе битовых карт}

Данные индексы можно рассматривать как модель проверки существования записи в
массиве данных.

Фильтр Блума --- алгоритм используемый для проверки существования записи.

Фильтр Блума использует массив бит размером $m$ и $k$ хеш-функций, каждая из
которых сопоставляет ключ с одну из $m$ позиций. Для добавления элемента в
множество существующих значений ключ подается на вход каждой хеш-функции,
возвращающих позицию бита, который должен быть установлен в единицу. Для проверки
принадлежности ключа множеству, ключ также подается на вход $k$ хеш-функций.
Если какой-либо бит, соответствующий одной из возращенных позиций, равен нулю,
то ключ не входит во множество. Из этого следует, что данный алгоритм гарантирует
отсутсвие ложноотрицательных результатов.

\imgs{bloom}{h!}{0.3}{Bitmap-индексы}

%\textit{Может со 100\%-ной вероятностью сказать, что элемент отсутсвует в
%наборе, но то, что элемент присутсвует в наборе, со 100\%-ной вероятностью он
%сказать не может (возможны ложноположительные результаты)}

В случае индексов существования необходимо обучить функцию таким образом, чтобы
среди возвращенных значений для множества ключей были коллизии, аналогично для
множества неключей, но при этом не было коллизий возращенных значений для ключей
и неключей. 

В отличие от оригинального фильтра Блума, где $FNR = 0$, $FPR = const$, где
const выбрано априори, при обучении достигается заданное значение $FPR$ при $FNR
= 0$ на реальных запросах.
